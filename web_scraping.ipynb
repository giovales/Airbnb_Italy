{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installing and importing the necessary libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: selenium in c:\\users\\trabalho\\appdata\\roaming\\python\\python310\\site-packages (4.20.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\programdata\\anaconda3\\lib\\site-packages (4.11.1)\n",
      "Requirement already satisfied: webdriver_manager in c:\\users\\trabalho\\appdata\\roaming\\python\\python310\\site-packages (4.0.1)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\trabalho\\appdata\\roaming\\python\\python310\\site-packages (from selenium) (0.25.0)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (2022.12.7)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\trabalho\\appdata\\roaming\\python\\python310\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\users\\trabalho\\appdata\\roaming\\python\\python310\\site-packages (from selenium) (4.11.0)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (1.26.14)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.3.2.post1)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\trabalho\\appdata\\roaming\\python\\python310\\site-packages (from webdriver_manager) (1.0.1)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from webdriver_manager) (22.0)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from webdriver_manager) (2.28.1)\n",
      "Requirement already satisfied: sortedcontainers in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\trabalho\\appdata\\roaming\\python\\python310\\site-packages (from trio~=0.17->selenium) (1.2.1)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\trabalho\\appdata\\roaming\\python\\python310\\site-packages (from trio~=0.17->selenium) (23.2.0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\trabalho\\appdata\\roaming\\python\\python310\\site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: outcome in c:\\users\\trabalho\\appdata\\roaming\\python\\python310\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\trabalho\\appdata\\roaming\\python\\python310\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->webdriver_manager) (2.0.4)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\trabalho\\appdata\\roaming\\python\\python310\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium beautifulsoup4 webdriver_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Opening the website using ChromeDriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the path to chromedriver\n",
    "driver_path = r'C:\\Users\\Trabalho\\Downloads\\chromedriver_win32\\chromedriver.exe'\n",
    "download_dir = os.path.join(os.getcwd(), 'Airbnb_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Service class is used to start the Chrome WebDriver instance\n",
    "service = Service()\n",
    "\n",
    "# webdriver.ChromeOptions is used to define the preference for the Chrome browser\n",
    "options = webdriver.ChromeOptions()\n",
    "prefs = {'download.default_directory': download_dir} # Define the download directory\n",
    "\n",
    "# Start the  Chrome WebDriver instance\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the page we want\n",
    "url = 'https://insideairbnb.com/get-the-data/'\n",
    "\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloading and separating the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded listings.csv.gz in bergamo\n",
      "Downloaded calendar.csv.gz in bergamo\n",
      "Downloaded reviews.csv.gz in bergamo\n",
      "Downloaded listings.csv in bergamo\n",
      "Downloaded reviews.csv in bergamo\n",
      "Downloaded neighbourhoods.csv in bergamo\n",
      "Downloaded neighbourhoods.geojson in bergamo\n",
      "Downloaded listings.csv.gz in bologna\n",
      "Downloaded calendar.csv.gz in bologna\n",
      "Downloaded reviews.csv.gz in bologna\n",
      "Downloaded listings.csv in bologna\n",
      "Downloaded reviews.csv in bologna\n",
      "Downloaded neighbourhoods.csv in bologna\n",
      "Downloaded neighbourhoods.geojson in bologna\n",
      "Downloaded listings.csv.gz in florence\n",
      "Downloaded calendar.csv.gz in florence\n",
      "Downloaded reviews.csv.gz in florence\n",
      "Downloaded listings.csv in florence\n",
      "Downloaded reviews.csv in florence\n",
      "Downloaded neighbourhoods.csv in florence\n",
      "Downloaded neighbourhoods.geojson in florence\n",
      "Downloaded listings.csv.gz in milan\n",
      "Downloaded calendar.csv.gz in milan\n",
      "Downloaded reviews.csv.gz in milan\n",
      "Downloaded listings.csv in milan\n",
      "Downloaded reviews.csv in milan\n",
      "Downloaded neighbourhoods.csv in milan\n",
      "Downloaded neighbourhoods.geojson in milan\n",
      "Downloaded listings.csv.gz in naples\n",
      "Downloaded calendar.csv.gz in naples\n",
      "Downloaded reviews.csv.gz in naples\n",
      "Downloaded listings.csv in naples\n",
      "Downloaded reviews.csv in naples\n",
      "Downloaded neighbourhoods.csv in naples\n",
      "Downloaded neighbourhoods.geojson in naples\n",
      "Downloaded listings.csv.gz in puglia\n",
      "Downloaded calendar.csv.gz in puglia\n",
      "Downloaded reviews.csv.gz in puglia\n",
      "Downloaded listings.csv in puglia\n",
      "Downloaded reviews.csv in puglia\n",
      "Downloaded neighbourhoods.csv in puglia\n",
      "Downloaded neighbourhoods.geojson in puglia\n",
      "Downloaded listings.csv.gz in rome\n",
      "Downloaded calendar.csv.gz in rome\n",
      "Downloaded reviews.csv.gz in rome\n",
      "Downloaded listings.csv in rome\n",
      "Downloaded reviews.csv in rome\n",
      "Downloaded neighbourhoods.csv in rome\n",
      "Downloaded neighbourhoods.geojson in rome\n",
      "Downloaded listings.csv.gz in sicily\n",
      "Downloaded calendar.csv.gz in sicily\n",
      "Downloaded reviews.csv.gz in sicily\n",
      "Downloaded listings.csv in sicily\n",
      "Downloaded reviews.csv in sicily\n",
      "Downloaded neighbourhoods.csv in sicily\n",
      "Downloaded neighbourhoods.geojson in sicily\n",
      "Downloaded listings.csv.gz in trentino\n",
      "Downloaded calendar.csv.gz in trentino\n",
      "Downloaded reviews.csv.gz in trentino\n",
      "Downloaded listings.csv in trentino\n",
      "Downloaded reviews.csv in trentino\n",
      "Downloaded neighbourhoods.csv in trentino\n",
      "Downloaded neighbourhoods.geojson in trentino\n",
      "Downloaded listings.csv.gz in venice\n",
      "Downloaded calendar.csv.gz in venice\n",
      "Downloaded reviews.csv.gz in venice\n",
      "Downloaded listings.csv in venice\n",
      "Downloaded reviews.csv in venice\n",
      "Downloaded neighbourhoods.csv in venice\n",
      "Downloaded neighbourhoods.geojson in venice\n"
     ]
    }
   ],
   "source": [
    "# Get the HTML \n",
    "html = driver.page_source\n",
    "\n",
    "# Analyze the HTML using BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Find all the links that starts with \"https://data.insideairbnb.com/italy\" to extract all data from Italy\n",
    "links = soup.find_all('a', href=True)\n",
    "download_links = [link['href'] for link in links if link['href'].startswith('https://data.insideairbnb.com/italy')]\n",
    "\n",
    "# Create a subfolder to save all the downloaded files\n",
    "os.makedirs('downloads', exist_ok=True)\n",
    "\n",
    "# Download all the files separating them by cities\n",
    "for link in download_links:\n",
    "    # Extract the city name from the URL\n",
    "    parsed_url = urlparse(link)\n",
    "    cidade = parsed_url.path.split('/')[3]  # Index 3 has the city name\n",
    "    file_name = link.split('/')[-1]  # Subfile name\n",
    "    folder_path = os.path.join('downloads', cidade)\n",
    "    os.makedirs(folder_path, exist_ok=True)  # Create a folder for each city\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    response = requests.get(link)\n",
    "    with open(file_path, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "    print(f'Downloaded {file_name} in {cidade}')\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unzziping the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import shutil\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging configuration to receive the feedbacks step by step from the code\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Path to the main folder where all the subfolders with the .gz files are\n",
    "downloads_dir = r'D:\\Nuvem\\OneDrive - Indra\\Área de Trabalho\\DATAGLOWUP_34\\downloads'\n",
    "\n",
    "# List of .gz file names and their new names after unzipping. The file_mapping maps the .gz file's name\n",
    "file_mappings = {\n",
    "    'calendar.csv.gz': 'calendar_2.csv',\n",
    "    'listings.csv.gz': 'listings_2.csv',\n",
    "    'reviews.csv.gz': 'reviews_2.csv'\n",
    "}\n",
    "\n",
    "# Function to unzip a .gz file, rename it and delete the original\n",
    "def decompress_and_rename(gz_file_path, output_file_path):\n",
    "    try:\n",
    "        with gzip.open(gz_file_path, 'rb') as f_in:\n",
    "            with open(output_file_path, 'wb') as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "        logging.info(f'Descompactação bem-sucedida: {gz_file_path} para {output_file_path}')\n",
    "        \n",
    "        # Delete the original .gz file\n",
    "        os.remove(gz_file_path)\n",
    "        logging.info(f'Arquivo original excluído: {gz_file_path}')\n",
    "    except Exception as e:\n",
    "        logging.error(f'Erro ao descompactar {gz_file_path}: {e}')\n",
    "\n",
    "\n",
    "# Run through all the subfolders in the main folder\n",
    "for root, dirs, files in os.walk(downloads_dir):\n",
    "    for file in files:\n",
    "        if file in file_mappings:\n",
    "            gz_file_path = os.path.join(root, file)\n",
    "            new_file_name = file_mappings[file]\n",
    "            output_file_path = os.path.join(root, new_file_name)\n",
    "            logging.info(f'Descompactando {gz_file_path} para {output_file_path}')\n",
    "            decompress_and_rename(gz_file_path, output_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
